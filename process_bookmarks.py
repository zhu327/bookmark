import subprocess
import sys
import os
import re
import requests
import random

from markdownify import markdownify as md

# --- [æ–°å¢] å…¨å±€é…ç½®å¸¸é‡ ---
# è¾“å…¥æ–‡ä»¶ï¼Œè„šæœ¬å°†æ£€æŸ¥æ­¤æ–‡ä»¶çš„ git diff
INPUT_FILE = "README.md"
# è‡ªåŠ¨å½’æ¡£çš„ç›®æ ‡æ–‡ä»¶
CATEGORY_FILE = "category.md"


# --- [æ–°å¢] ä»ç¯å¢ƒå˜é‡è·å– LLM API é…ç½® ---
def get_api_config() -> dict | None:
    """
    ä»ç¯å¢ƒå˜é‡ä¸­è·å–å¹¶éªŒè¯ LLM API é…ç½®ã€‚

    Returns:
        dict: åŒ…å« api_url, api_key, model çš„å­—å…¸ï¼Œå¦‚æœç¼ºå°‘ä»»ä½•å¿…è¦é…ç½®åˆ™è¿”å› Noneã€‚
    """
    # ä»ç¯å¢ƒå˜é‡è·å– API URLï¼Œè¿™æ˜¯å¿…éœ€çš„
    api_url = os.getenv("LLM_API_URL")
    if not api_url:
        print("é”™è¯¯: ç¼ºå°‘ç¯å¢ƒå˜é‡ 'LLM_API_URL'ã€‚è¯·è®¾ç½® API çš„è¯·æ±‚åœ°å€ã€‚", file=sys.stderr)
        return None

    # ä»ç¯å¢ƒå˜é‡è·å– API Keyï¼Œè¿™æ˜¯å¿…éœ€çš„
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        print("é”™è¯¯: ç¼ºå°‘ç¯å¢ƒå˜é‡ 'OPENAI_API_KEY'ã€‚è¯·è®¾ç½®æ‚¨çš„ API å¯†é’¥ã€‚", file=sys.stderr)
        return None

    # ä»ç¯å¢ƒå˜é‡è·å–æ¨¡å‹åç§°ï¼Œå¦‚æœæœªè®¾ç½®åˆ™ä½¿ç”¨é»˜è®¤å€¼
    model = os.getenv("LLM_MODEL_NAME", "deepseek-ai/DeepSeek-R1-0528-Qwen3-8B")

    return {"api_url": api_url, "api_key": api_key, "model": model}


# --- [æ–°å¢] ä»ç¯å¢ƒå˜é‡è·å– Cloudflare API é…ç½® ---
def get_cloudflare_config() -> dict | None:
    """
    ä»ç¯å¢ƒå˜é‡ä¸­è·å–å¹¶éªŒè¯ Cloudflare API é…ç½®ã€‚

    Returns:
        dict: åŒ…å« account_id å’Œ api_token çš„å­—å…¸ï¼Œå¦‚æœç¼ºå°‘åˆ™è¿”å› Noneã€‚
    """
    account_id = os.getenv("CLOUDFLARE_ACCOUNT_ID")
    if not account_id:
        print("é”™è¯¯: ç¼ºå°‘ç¯å¢ƒå˜é‡ 'CLOUDFLARE_ACCOUNT_ID'ã€‚æ— æ³•ä½¿ç”¨ Cloudflare è·å–å¾®ä¿¡æ–‡ç« ã€‚", file=sys.stderr)
        return None

    api_token = os.getenv("CLOUDFLARE_API_TOKEN")
    if not api_token:
        print("é”™è¯¯: ç¼ºå°‘ç¯å¢ƒå˜é‡ 'CLOUDFLARE_API_TOKEN'ã€‚æ— æ³•ä½¿ç”¨ Cloudflare è·å–å¾®ä¿¡æ–‡ç« ã€‚", file=sys.stderr)
        return None

    return {"account_id": account_id, "api_token": api_token}


# --- [å·²ä¿®æ”¹] ä½¿ç”¨ç¯å¢ƒå˜é‡é…ç½®çš„ OpenAI API å‡½æ•° ---
def summarize_with_openai(content: str) -> str | None:
    """
    ä½¿ç”¨é…ç½®å¥½çš„ OpenAI API ä¸ºç»™å®šæ–‡æœ¬ç”Ÿæˆæ‘˜è¦ã€‚
    """
    config = get_api_config()
    if not config:
        return None

    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {config['api_key']}"
    }
    system_prompt = "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„æ–‡ç« æ‘˜è¦åŠ©æ‰‹ã€‚è¯·å°†ä»¥ä¸‹æ–‡ç« å†…å®¹ç”Ÿæˆä¸€æ®µç²¾ç‚¼çš„ä¸­æ–‡æ‘˜è¦ï¼Œè¦æ±‚è¯­è¨€æµç•…ã€æŠ“ä½æ ¸å¿ƒè¦ç‚¹ï¼Œå¹¶ä¸¥æ ¼æ§åˆ¶åœ¨150ä¸ªå­—ä»¥å†…ã€‚"
    payload = {
        "model": config['model'],
        "messages": [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": content}
        ],
        "temperature": 0.3,
    }

    try:
        print("    > æ­£åœ¨é€šè¿‡ requests è¯·æ±‚ LLM ç”Ÿæˆæ‘˜è¦...")
        response = requests.post(config['api_url'], headers=headers, json=payload, timeout=600)
        response.raise_for_status()
        response_data = response.json()
        summary = response_data['choices'][0]['message']['content']
        return summary.strip()
    except requests.RequestException as e:
        print(f"    > LLM API è¯·æ±‚å¤±è´¥ (ç½‘ç»œé”™è¯¯): {e}", file=sys.stderr)
        if e.response is not None:
             print(f"    > å“åº”å†…å®¹: {e.response.text}", file=sys.stderr)
        return None
    except (KeyError, IndexError) as e:
        print(f"    > è§£æ LLM å“åº”å¤±è´¥: æ„å¤–çš„æ ¼å¼ã€‚é”™è¯¯: {e}", file=sys.stderr)
        return None


# --- [å·²ä¿®æ”¹] ä½¿ç”¨ç¯å¢ƒå˜é‡é…ç½®çš„ AI åˆ†ç±»å‡½æ•° ---
def categorize_with_openai(title: str, summary: str, existing_categories: list[str]) -> str | None:
    """
    ä½¿ç”¨é…ç½®å¥½çš„ OpenAI API å¯¹æ–‡ç« è¿›è¡Œåˆ†ç±»ã€‚
    """
    config = get_api_config()
    if not config:
        return None

    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {config['api_key']}"
    }
    category_list_str = "\n".join(f"- {cat}" for cat in existing_categories)
    system_prompt = (
        "ä½ æ˜¯ä¸€ä½æ™ºèƒ½åˆ†ç±»åŠ©æ‰‹ã€‚ä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®æ–‡ç« çš„æ ‡é¢˜å’Œæ‘˜è¦ï¼Œå°†å…¶åˆ†é…åˆ°ä¸€ä¸ªæœ€åˆé€‚çš„ç±»åˆ«ä¸­ã€‚"
        "è¯·ä¸¥æ ¼ä»ä»¥ä¸‹ã€å·²æœ‰ç±»åˆ«ã€‘åˆ—è¡¨ä¸­é€‰æ‹©ä¸€ä¸ªã€‚å¦‚æœæ‰€æœ‰ç±»åˆ«éƒ½ä¸å¤ªåˆé€‚ï¼Œè¯·åˆ›é€ ä¸€ä¸ªæ–°çš„ã€ç®€æ´çš„ç±»åˆ«åç§°ï¼ˆä¾‹å¦‚ 'äº‘åŸç”ŸæŠ€æœ¯' æˆ– 'äº§å“ä¸è®¾è®¡'ï¼‰ã€‚"
        "ä½ çš„å›ç­”å¿…é¡»ä¸”åªèƒ½æ˜¯ç±»åˆ«åç§°æœ¬èº«ï¼Œä¸è¦åŒ…å«ä»»ä½•å¤šä½™çš„æ–‡å­—ã€è§£é‡Šæˆ–æ ‡ç‚¹ç¬¦å·ï¼ˆå¦‚ 'ç±»åˆ«ï¼š' æˆ– '##'ï¼‰ã€‚"
    )
    user_content = f"""
ã€å·²æœ‰ç±»åˆ«ã€‘:
{category_list_str}

ã€æ–‡ç« æ ‡é¢˜ã€‘:
{title}

ã€æ–‡ç« æ‘˜è¦ã€‘:
{summary}

è¯·ä¸ºä»¥ä¸Šå†…å®¹é€‰æ‹©æˆ–åˆ›å»ºä¸€ä¸ªæœ€åˆé€‚çš„ç±»åˆ«åç§°ï¼š
"""
    payload = {
        "model": config['model'],
        "messages": [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_content.strip()}
        ],
        "temperature": 0.1,
    }

    try:
        print("    > æ­£åœ¨é€šè¿‡ requests è¯·æ±‚ LLM è¿›è¡Œåˆ†ç±»...")
        response = requests.post(config['api_url'], headers=headers, json=payload, timeout=600)
        response.raise_for_status()
        response_data = response.json()
        category = response_data['choices'][0]['message']['content'].strip()
        # ç§»é™¤AIå¯èƒ½è¿”å›çš„å¤šä½™å­—ç¬¦
        category = re.sub(r'^[#*"\s]+|[#*"\s]+$', '', category)
        return category
    except requests.RequestException as e:
        print(f"    > LLM API åˆ†ç±»è¯·æ±‚å¤±è´¥ (ç½‘ç»œé”™è¯¯): {e}", file=sys.stderr)
        if e.response is not None:
             print(f"    > å“åº”å†…å®¹: {e.response.text}", file=sys.stderr)
        return None
    except (KeyError, IndexError) as e:
        print(f"    > è§£æ LLM åˆ†ç±»å“åº”å¤±è´¥: æ„å¤–çš„æ ¼å¼ã€‚é”™è¯¯: {e}", file=sys.stderr)
        return None


# --- [æ–°å¢] ä½¿ç”¨ Cloudflare è·å–å¾®ä¿¡å…¬ä¼—å·å†…å®¹ ---
def fetch_content_with_cloudflare(url: str) -> str | None:
    """
    ä½¿ç”¨ Cloudflare æµè§ˆå™¨æ¸²æŸ“å’Œ AI Markdown è½¬æ¢è·å–æ–‡ç« å†…å®¹ã€‚
    ä¸“ä¸ºè§£å†³å¾®ä¿¡å…¬ä¼—å·ç­‰éš¾ä»¥æŠ“å–çš„ç½‘ç«™è®¾è®¡ã€‚
    """
    config = get_cloudflare_config()
    if not config:
        return None

    account_id = config["account_id"]
    api_token = config["api_token"]

    headers = {"Authorization": f"Bearer {api_token}"}

    # ç¬¬ 1 æ­¥: ä½¿ç”¨æµè§ˆå™¨æ¸²æŸ“è·å– HTML
    render_url = f"https://api.cloudflare.com/client/v4/accounts/{account_id}/browser-rendering/content"
    render_payload = {"url": url}
    
    try:
        print(f"    > æ­£åœ¨é€šè¿‡ Cloudflare æµè§ˆå™¨æ¸²æŸ“è·å– HTML: {url}")
        # æ¸²æŸ“å¯èƒ½è€—æ—¶è¾ƒé•¿ï¼Œè®¾ç½®æ›´é•¿çš„è¶…æ—¶æ—¶é—´
        response = requests.post(render_url, headers={"Content-Type": "application/json", **headers}, json=render_payload, timeout=600)
        response.raise_for_status()
        render_data = response.json()

        if not render_data.get("success"):
            print(f"    > Cloudflare æµè§ˆå™¨æ¸²æŸ“å¤±è´¥: {render_data.get('errors')}", file=sys.stderr)
            return None
        
        html_content = render_data['result']

    except requests.RequestException as e:
        print(f"    > Cloudflare æµè§ˆå™¨æ¸²æŸ“è¯·æ±‚å¤±è´¥: {e}", file=sys.stderr)
        if e.response is not None:
             print(f"    > å“åº”å†…å®¹: {e.response.text}", file=sys.stderr)
        return None
    except (KeyError, TypeError):
        print(f"    > Cloudflare æµè§ˆå™¨æ¸²æŸ“å“åº”æ ¼å¼ä¸æ­£ç¡®ã€‚", file=sys.stderr)
        return None

    # ç¬¬ 2 æ­¥: å°† HTML è½¬æ¢ä¸º Markdown
    return md(html_content).strip()


# --- Jina Reader å‡½æ•° (ä¿æŒä¸å˜) ---
def fetch_content_with_jina(url: str) -> str | None:
    jina_reader_url = f"https://r.jina.ai/{url}"
    headers = {"Accept": "text/plain", "User-Agent": "MyBookmarkProcessor/1.0"}
    try:
        print(f"    > æ­£åœ¨é€šè¿‡ Jina Reader è·å–å†…å®¹: {url}")
        response = requests.get(jina_reader_url, headers=headers, timeout=60)
        response.raise_for_status()
        full_text = response.text
        if "Markdown Content:\n" in full_text:
            content_part = full_text.split("Markdown Content:\n", 1)[1]
            return content_part.strip()
        else:
            print("    > è­¦å‘Š: Jina Reader æœªè¿”å›é¢„æœŸçš„ 'Markdown Content:' æ ¼å¼ã€‚", file=sys.stderr)
            return full_text.strip()
    except requests.RequestException as e:
        print(f"    > Jina Reader API è¯·æ±‚å¤±è´¥: {e}", file=sys.stderr)
        return None


# --- [æ–°å¢] å†…å®¹è·å–è°ƒåº¦å‡½æ•° ---
def fetch_article_content(url: str) -> str | None:
    """
    æ ¹æ® URL ç±»å‹é€‰æ‹©åˆé€‚çš„æŠ“å–å™¨ (Cloudflare æˆ– Jina)ã€‚
    ä¼˜å…ˆå¤„ç†å¾®ä¿¡å…¬ä¼—å·é“¾æ¥ã€‚
    """
    if "mp.weixin.qq.com" in url:
        print("  > æ£€æµ‹åˆ°å¾®ä¿¡å…¬ä¼—å·é“¾æ¥ï¼Œå°†ä½¿ç”¨ Cloudflare æŠ“å–...")
        return fetch_content_with_cloudflare(url)
    else:
        print("  > ä½¿ç”¨ Jina Reader æŠ“å–...")
        return fetch_content_with_jina(url)


# --- Git å’Œè§£æç›¸å…³çš„å‡½æ•° (ä¿æŒä¸å˜) ---
def parse_markdown_links_from_diff(diff_text: str) -> list:
    link_pattern = re.compile(r'\[(.+?)\]\((.+?)\)')
    extracted_links = []
    for line in diff_text.splitlines():
        if line.startswith('+') and not line.startswith('+++'):
            content = line[1:].strip()
            matches = link_pattern.findall(content)
            for title, url in matches:
                extracted_links.append({'title': title.strip(), 'url': url.strip()})
    return extracted_links

def get_file_last_change_diff_text(file_path: str, repo_path: str) -> str | None:
    if not os.path.isdir(os.path.join(repo_path, '.git')):
        print(f"é”™è¯¯: '{repo_path}' ä¸æ˜¯ä¸€ä¸ªæœ‰æ•ˆçš„ Git ä»“åº“ã€‚", file=sys.stderr)
        return None
    try:
        log_command = ['git', 'log', '-n', '2', '--pretty=%H', '--', file_path]
        result = subprocess.run(log_command, cwd=repo_path, capture_output=True, text=True, check=True)
        hashes = [h for h in result.stdout.strip().split('\n') if h]
    except subprocess.CalledProcessError as e:
        print(f"é”™è¯¯ï¼šæ— æ³•è·å– '{file_path}' çš„æäº¤å†å²: {e.stderr.strip()}", file=sys.stderr)
        return None
    if len(hashes) < 2:
        print(f"æ–‡ä»¶ '{file_path}' åªæœ‰ä¸€ä¸ªæˆ–æ²¡æœ‰å˜æ›´å†å²ï¼Œæ— æ³•è¿›è¡Œå¯¹æ¯”ã€‚")
        return None
    newer_commit, older_commit = hashes[0], hashes[1]
    print(f"å¯¹æ¯”æ–‡ä»¶ '{file_path}' çš„æœ€åä¸¤æ¬¡å˜æ›´ (from {older_commit[:7]} to {newer_commit[:7]})")
    print("=" * 60)
    try:
        diff_command = ['git', 'diff', older_commit, newer_commit, '--', file_path]
        diff_result = subprocess.run(diff_command, cwd=repo_path, capture_output=True, text=True, check=True)
        return diff_result.stdout
    except subprocess.CalledProcessError as e:
        print(f"é”™è¯¯ï¼šæ‰§è¡Œ git diff å¤±è´¥: {e.stderr.strip()}", file=sys.stderr)
        return None


# --- æ–‡ä»¶å¤„ç†å‡½æ•° ---
def parse_categories_from_file(file_path: str) -> list[str]:
    """
    ä»æ–‡ä»¶ä¸­è§£æH2(##)å’ŒH3(###)æ ‡é¢˜ä½œä¸ºåˆ†ç±»ã€‚
    """
    if not os.path.exists(file_path):
        return []
    categories = []
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if line.startswith('## ') or line.startswith('### '):
                    header_content = line.lstrip('#').strip()
                    parts = header_content.split(maxsplit=1)
                    category_name = parts[-1]
                    categories.append(category_name)
    except IOError as e:
        print(f"é”™è¯¯: æ— æ³•è¯»å–åˆ†ç±»æ–‡ä»¶ '{file_path}': {e}", file=sys.stderr)
    return categories

def insert_article_to_category_file(file_path: str, category: str, title: str, url: str, summary: str):
    """
    å°†æ–‡ç« æ’å…¥åˆ°æŒ‡å®šçš„åˆ†ç±»ä¸‹ï¼Œæ”¯æŒH2å’ŒH3çº§åˆ«çš„åˆ†ç±»ã€‚
    """
    try:
        if not os.path.exists(file_path):
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(f"# ç½‘ç«™èµ„æºåˆ†ç±»æ•´ç†\n\n")
        with open(file_path, 'r', encoding='utf-8') as f:
            lines = f.readlines()
    except IOError as e:
        print(f"é”™è¯¯: è¯»å†™æ–‡ä»¶ '{file_path}' å¤±è´¥: {e}", file=sys.stderr)
        return

    article_text = f"**æ ‡é¢˜:** {title}\n\n**é“¾æ¥:** {url}\n\n**æ‘˜è¦:** {summary}"
    category_header_index = -1

    for i, line in enumerate(lines):
        stripped_line = line.strip()
        if stripped_line.startswith('## ') or stripped_line.startswith('### '):
            header_content = stripped_line.lstrip('#').strip()
            parts = header_content.split(maxsplit=1)
            name_in_header = parts[-1]
            if name_in_header == category:
                category_header_index = i
                break

    if category_header_index != -1:
        print(f"    > åˆ†ç±» '{category}' å·²å­˜åœ¨ï¼Œæ­£åœ¨æŸ¥æ‰¾æ’å…¥ä½ç½®...")
        first_article_index = -1
        for i in range(category_header_index + 1, len(lines)):
            if lines[i].strip().startswith("**æ ‡é¢˜:**"):
                first_article_index = i
                break

        if first_article_index != -1:
            insertion_text = f"{article_text}\n\n---\n\n"
            lines.insert(first_article_index, insertion_text)
            print(f"    -> æˆåŠŸå°†æ–‡ç« æ’å…¥åˆ° '{category}' åˆ†ç±»é¡¶éƒ¨ã€‚")
        else:
            end_of_section_index = len(lines)
            for i in range(category_header_index + 1, len(lines)):
                if lines[i].startswith("##"):
                    end_of_section_index = i
                    break
            insertion_text = f"\n{article_text}\n"
            lines.insert(end_of_section_index, insertion_text)
            print(f"    -> æˆåŠŸå°†æ–‡ç« æ·»åŠ åˆ°ç©ºçš„ '{category}' åˆ†ç±»ä¸‹ã€‚")
    else:
        print(f"    > åˆ†ç±» '{category}' æ˜¯æ–°åˆ†ç±»ï¼Œå°†åœ¨æ–‡ä»¶æœ«å°¾åˆ›å»ºã€‚")
        if lines and not lines[-1].endswith('\n'):
            lines.append("\n")
        if lines and lines[-1].strip() != "":
            lines.append("\n")
        emojis = ["ğŸ§©", "ğŸ”§", "ğŸ’¡", "ğŸ“š", "ğŸ§­", "âœ¨"]
        new_category_header = f"## {random.choice(emojis)} {category}\n"
        lines.append(new_category_header)
        lines.append("\n")
        lines.append(f"{article_text}\n")

    try:
        with open(file_path, 'w', encoding='utf-8') as f:
            f.writelines(lines)
    except IOError as e:
        print(f"é”™è¯¯: å†™å…¥æ–‡ä»¶ '{file_path}' å¤±è´¥: {e}", file=sys.stderr)


# --- [å·²ä¿®æ”¹] ä¸»ç¨‹åºå…¥å£ ---
if __name__ == "__main__":
    print("=" * 60)
    print("ğŸš€ å¯åŠ¨è‡ªåŠ¨åŒ–ä¹¦ç­¾å¤„ç†ä¸å½’æ¡£è„šæœ¬ ğŸš€")
    
    # æ£€æŸ¥ API é…ç½®æ˜¯å¦é½å…¨
    api_config = get_api_config()
    if not api_config:
        print("å¯åŠ¨å¤±è´¥ï¼šè¯·å…ˆæ ¹æ®æç¤ºè®¾ç½®å¥½å¿…è¦çš„ LLM ç¯å¢ƒå˜é‡ã€‚", file=sys.stderr)
        sys.exit(1)

    print(f"  - è¾“å…¥æ–‡ä»¶: {INPUT_FILE}")
    print(f"  - å½’æ¡£æ–‡ä»¶: {CATEGORY_FILE}")
    print(f"  - LLM æ¨¡å‹: {api_config['model']}")
    print("-" * 60)

    # ä»“åº“è·¯å¾„ï¼Œé»˜è®¤ä¸ºå½“å‰ç›®å½•ï¼Œä¹Ÿå¯é€šè¿‡ç¯å¢ƒå˜é‡é…ç½®
    repository_path = os.getenv("GIT_REPO_PATH", ".")
    
    # è·å–æ–‡ä»¶å˜æ›´
    diff_output = get_file_last_change_diff_text(INPUT_FILE, repository_path)

    if diff_output:
        extracted_links = parse_markdown_links_from_diff(diff_output)

        if not extracted_links:
            print("åœ¨æœ¬æ¬¡å˜æ›´ä¸­æ²¡æœ‰æ‰¾åˆ°æ–°å¢çš„ Markdown é“¾æ¥ã€‚")
        else:
            print(f"è§£æåˆ° {len(extracted_links)} ä¸ªæ–°å¢é“¾æ¥ï¼Œæ­£åœ¨å¤„ç†...\n")
            
            print(f"--- å‡†å¤‡å·¥ä½œ ---")
            print(f"  > æ­£åœ¨ä» '{CATEGORY_FILE}' è§£æç°æœ‰åˆ†ç±»...")
            existing_categories = parse_categories_from_file(CATEGORY_FILE)
            if existing_categories:
                print(f"  > å·²æ‰¾åˆ° {len(existing_categories)} ä¸ªåˆ†ç±»: {', '.join(existing_categories)}\n")
            else:
                print(f"  > æœªæ‰¾åˆ°ä»»ä½•ç°æœ‰åˆ†ç±»ï¼Œå°†ç”± AI è‡ªåŠ¨åˆ›å»ºã€‚\n")

            for i, link_data in enumerate(extracted_links):
                print(f"--- å¤„ç†ç¬¬ {i+1}/{len(extracted_links)} ä¸ªé“¾æ¥ ---")
                print(f"  åŸå§‹æ ‡é¢˜: {link_data['title']}")
                print(f"  åŸå§‹é“¾æ¥: {link_data['url']}")

                # [ä¿®æ”¹] ä½¿ç”¨æ–°çš„è°ƒåº¦å‡½æ•°è·å–å†…å®¹
                content = fetch_article_content(link_data['url'])

                if content:
                    summary = summarize_with_openai(content)
                    if summary:
                        print(f"  AI æ‘˜è¦: {summary}")
                        
                        chosen_category = categorize_with_openai(
                            link_data['title'], 
                            summary, 
                            existing_categories
                        )
                        
                        if chosen_category:
                            print(f"  AI åˆ†ç±»: {chosen_category}")
                            insert_article_to_category_file(
                                CATEGORY_FILE,
                                chosen_category,
                                link_data['title'],
                                link_data['url'],
                                summary
                            )
                            # å¦‚æœAIåˆ›å»ºäº†ä¸€ä¸ªå…¨æ–°çš„åˆ†ç±»ï¼Œå°†å…¶åŠ å…¥åˆ—è¡¨ï¼Œä¾›åç»­é“¾æ¥ä½¿ç”¨
                            if chosen_category not in existing_categories:
                                existing_categories.append(chosen_category)
                            print(f"  [æˆåŠŸ] æ–‡ç« å·²è‡ªåŠ¨å½’æ¡£åˆ° '{CATEGORY_FILE}'ã€‚\n")
                        else:
                            print("  [å¤±è´¥] AI åˆ†ç±»ç”Ÿæˆå¤±è´¥ï¼Œè·³è¿‡å½’æ¡£ã€‚\n")
                    else:
                        print("  AI æ‘˜è¦: ç”Ÿæˆå¤±è´¥ã€‚\n")
                else:
                    print("  å†…å®¹è·å–: å¤±è´¥ï¼Œè·³è¿‡æ‘˜è¦ç”Ÿæˆã€‚\n")
            print("=" * 60)
            print("æ‰€æœ‰é“¾æ¥å¤„ç†å®Œæ¯•ã€‚")
    print("=" * 60)